---
agency: Artificial Intelligence
title: Equitably Leveraging the Power of Big Data
subtitle: As a nation, we have yet to grasp the full benefits or unwanted effects of artificial intelligence. AI is widely used, but how do we know it's working appropriately?
permalink: /what-we-deliver/doj-crt/
redirect_from: /project/doj-crt/
excerpt: With AI and Machine Learning (ML) already changing the way in which society addresses economic and national security challenges and opportunities, these technologies must be developed and used in a trustworthy and responsible manner.
image: /assets/emergingtech/ai.gif
image_accessibility: AI
image_icon:
project_weight: 12
tag: civil rights
expiration_date:
project_url: 
learn_more:
product_clients:
resources:
  - "[Congressional Research Service](https://crsreports.congress.gov/product/pdf/R/R46795)"
  - "[Government Accountability Office](https://www.gao.gov/products/gao-21-519sp)"
  - "[The National Security Commission on Artificial Intelligence](https://www.nscai.gov/)"
  - "[The Global Partnership on Artificial Intelligence](https://gpai.ai/)"
  - "[National Artificial Intelligence Initiative](https://ai.gov)"
  - "[National Institute of Standards and Technology](https://nist.gov)"
github_repo:
  - "[Association for Computing Machinery (ACM)](https://www.acm.org/education/ai-ml-techtalks)"
  - "[AI Now Institute (NYU)](https://ainowinstitute.org/)"
  - "[AI Sustainability Center](https://aisustainability.org/)"
  - "[ALJ-Algorithmic Justice League](https://www.ajlunited.org/)"
  - "[Allen Institute for Artificial Intelligence (AI2)](https://allenai.org/)"
  - "[Association for the Advancement of AI](https://www.aaai.org/)"
  - "[The Alan Turing Institute](https://www.turing.ac.uk/)"
  - "[Berkeley Center for Law & Technology](https://www.law.berkeley.edu/research/bclt/)"
  - "[Center for AI and Digital Policy](https://www.caidp.org/)"
  - "[Centre for the Study of Existental Risk (CSER)](https://www.cser.ac.uk/)"
  - "[Defense Advanced Research Projects Agency](https://www.darpa.mil/work-with-us/ai-next-campaign)"
  - "[Data & Society](https://datasociety.net/)"
  - "[Electronic Frontier Foundation](https://www.eff.org/)"
  - "[FTC Office of Technology Research and Investigation (OTech)](https://www.ftc.gov/about-ftc/bureaus-offices/bureau-consumer-protection/office-technology-research-investigation)"
  - "[Future of Humanity Institute (University of Oxford)](https://www.fhi.ox.ac.uk/)"
  - "[Future of Life Institute](https://futureoflife.org/)"
  - "[Future of Privacy Forum](https://fpf.org/)"
  - "[Governance Lab](https://thegovlab.org/)"
  - "[Institute of Electrical and Electronics Engineers (IEEE)](https://ethicsinaction.ieee.org/#set-the-standard)"
  - "[KPMG](https://advisory.kpmg.us/services/artificial-intelligence.html)"
  - "[Leverhulme Centre for the Future of Intelligence (CFI)](http://lcfi.ac.uk/)"
  - "[McKinsey](https://www.mckinsey.com/featured-insights/artificial-intelligence)"
  - "[MIT Computer Science & Artificial Intelligence Lab (MIT CSAIL)](https://www.csail.mit.edu/)"
  - "[MIT Media Lab](https://www.media.mit.edu/research/?filter=everything&tag=artificial-intelligence)"
  - "[Nesta - Mapping AI Governance](https://www.nesta.org.uk/data-visualisation-and-interactive/mapping-ai-governance/)"
  - "[National Institute of Standards and Technology, U.S. Department of Commerce (NIST)](https://www.nist.gov/artificial-intelligence)"
  - "[National Security Commission on Artificial Intelligence](https://www.nscai.gov/)"
  - "[Open Community for Ethics in Autonomous and Intelligent Systems (OCEANIS)](https://ethicsstandards.org/)"
  - "[OECD AI Policy Observatory](https://oecd.ai/)"
  - "[OpenAI](https://openai.com/)"
  - "[Open Data Institute](https://theodi.org/)"
  - "[Partnership on AI](https://www.partnershiponai.org/)"
  - "[Stanford University Human-Centered Artificial Intelligence (HAI)](https://hai.stanford.edu/)"
  - "[Tech Policy Lab (Univeristy of Washington)](http://techpolicylab.uw.edu/research_area/artificial-intelligence/)"
  - "[United Nations Interregional Crime and Justice Research Institute](http://www.unicri.it/security-through-research-technology-and-innovation)"
  - "[Next Generation Artificial Intelligence Research Center (University of Tokyo)](https://www.ai.u-tokyo.ac.jp/en/)"
  - "[World Economic Forum](https://www.weforum.org/platforms/shaping-the-future-of-technology-governance-artificial-intelligence-and-machine-learning)"
---

The field of artificial intelligence (AI)—a term first used in the 1950s—has gone through
multiple waves of advancement over the subsequent decades. Today, AI can broadly be thought
of as computerized systems that work and react in ways commonly thought to require intelligence, such as the ability to learn, solve problems, and achieve goals under uncertain and varying conditions. The field encompasses a range of methodologies and application areas, including machine learning (ML), natural language processing, and robotics.

In the past decade or so, increased computing power, the accumulation of big data, and advances in AI techniques have led to rapid growth in AI research and applications. Given these developments and the increasing application of AI technologies across economic sectors, stakeholders from academia, industry, and civil society have called for the federal government to become more knowledgeable about AI technologies and more proactive in considering public policies around their use.

<div class="testimonial-blockquote">
  We have seen AI providing conversation and comfort to the lonely; we have also seen AI engaging in racial discrimination. Yet the biggest harm that AI is likely to do to individuals in the short term is job displacement, as the amount of work we can automate with AI is vastly larger than before. As leaders, it is incumbent on all of us to make sure we are building a world in which every individual has an opportunity to thrive.
    <span>- Eric Schmidt, Chairman, NSCAI</span>
</div>

<div class="small-caps">Governance</div>

### Applicable Laws

At least four laws enacted in the 116th Congress focused on AI or included
AI-focused provisions.
- The [National Defense Authorization Act for FY2021 (P.L. 116-283)](https://www.congress.gov/bill/116th-congress/house-bill/6395#:~:text=Shown%20Here%3A-,Public%20Law%20No%3A%20116%2D283,(01%2F01%2F2021)&text=This%20bill%20authorizes%20FY2021%20appropriations,provided%20in%20subsequent%20appropriations%20legislation.) included provisions addressing various defense- and security-related AI activities, as well as the expansive National Artificial Intelligence Initiative Act of 2020 (Division E).
- The [Consolidated Appropriations Act, 2021 (P.L. 116-260)](https://www.congress.gov/bill/116th-congress/house-bill/133/text) included the AI in Government Act of 2020 (Division U, Title I), which directed the General Services Administration to create an AI Center of Excellence to facilitate the adoption of AI technologies in the federal government.
- The [Identifying Outputs of Generative Adversarial Networks (IOGAN) Act (P.L. 116-258)](https://www.congress.gov/bill/116th-congress/senate-bill/2904) supported research on Generative Adversarial Networks (GANs), the primary technology used to create deepfakes.
- [P.L. 116-94](https://www.congress.gov/bill/116th-congress/house-bill/1865/text) established a financial program related to exports in AI among other areas.

AI holds potential benefits and opportunities, but also challenges and pitfalls. For example, AI technologies can accelerate and provide insights into data processing; augment human decisionmaking; optimize performance for complex tasks and systems; and improve safety for people in dangerous occupations. On the other hand, AI systems may perpetuate or amplify
bias, may not yet be fully able to explain their decisionmaking, and often depend on vast datasets that are not widely accessible to facilitate research and development (R&D). Further, stakeholders have questioned the adequacy of human capital in both the public and private sectors to develop and work with AI, as well as the adequacy of current laws and
regulations for dealing with societal and ethical issues that may arise. Together, such challenges can lead to an inability to fully assess and understand the operations and outputs of AI systems—sometimes referred to as the “black box” problem.

Because of these questions and concerns, some stakeholders have advocated for slowing the pace of AI development and use until more research, policymaking, and preparation can occur. Others have countered that AI will make lives safer, healthier, and more productive, so the federal government should not attempt to slow it, but rather should give broad support to AI
technologies and increase federal AI funding.

In response to this debate, Congress has begun discussing issues such as the trustworthiness, potential bias, and ethical uses of AI; possible disruptive impacts to the U.S. workforce; the adequacy of U.S. expertise and training in AI; domestic and international efforts to set technological standards and testing benchmarks; and the level of U.S. federal investments in AI research and development and how that impacts U.S. international competitiveness. Congress is likely to continue grappling with these issues and working to craft policies that protect American citizens while maximizing U.S. innovation and leadership.

<div class="small-caps">Recent Events</div>

### Global Emerging Technology Summit 2021

<iframe width="560" height="315" src="https://www.youtube.com/embed/MkJs-eRPABg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
